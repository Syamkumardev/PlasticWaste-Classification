{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":497253,"sourceType":"datasetVersion","datasetId":233210}],"dockerImageVersionId":30839,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Waste Classification using CNN\n\n#### This notebook trains a Convolutional Neural Network (CNN) to classify different types of waste.\n#### The dataset is loaded, preprocessed, and fed into the model for training.\n#### We also implement techniques like , batch normalization, and early stopping to optimize performance.\n\n## Plastic Waste Classification using CNN\n\n\n* #### This notebook implements a Convolutional Neural Network (CNN) to classify plastic waste.\n* #### It includes dataset loading, preprocessing, data augmentation, model training, and evaluation.\n* #### The model is optimized using batch normalization, early stopping to optimize performance, and dropout.\n\n","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-01-30T06:13:00.243496Z","iopub.execute_input":"2025-01-30T06:13:00.244179Z","iopub.status.idle":"2025-01-30T06:14:00.151839Z","shell.execute_reply.started":"2025-01-30T06:13:00.244116Z","shell.execute_reply":"2025-01-30T06:14:00.150626Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Import necessary libraries\n\n### In this step, we import essential libraries required for:\n#### - Data manipulation (NumPy, Pandas)\n#### - Image processing (OpenCV, Matplotlib)\n#### - Deep learning (TensorFlow/Keras)\n#### - Performance monitoring (tqdm for progress tracking)\n","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\n\"\"\"\nWe begin by importing essential libraries for:\n- Data processing (NumPy, Pandas)\n- Image handling (OpenCV, Matplotlib)\n- Deep learning (TensorFlow/Keras)\n- Progress monitoring (tqdm)\n- System operations (os)\n\"\"\"\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport tensorflow as tf\nfrom tqdm import tqdm\nfrom glob import glob\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\n# Suppress warnings for clarity\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T06:14:00.153392Z","iopub.execute_input":"2025-01-30T06:14:00.153763Z","iopub.status.idle":"2025-01-30T06:14:00.168897Z","shell.execute_reply.started":"2025-01-30T06:14:00.153733Z","shell.execute_reply":"2025-01-30T06:14:00.167951Z"},"scrolled":true,"_kg_hide-input":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Verify TensorFlow installation and GPU availability\n\n#### Check the installed TensorFlow version and confirm if GPU is available for faster training.","metadata":{}},{"cell_type":"code","source":"# Verify TensorFlow installation and GPU availability\nprint(\"TensorFlow Version:\", tf.__version__)\nprint(\"Is GPU Available:\", tf.config.list_physical_devices('GPU'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T06:14:00.17065Z","iopub.execute_input":"2025-01-30T06:14:00.171192Z","iopub.status.idle":"2025-01-30T06:14:00.177241Z","shell.execute_reply.started":"2025-01-30T06:14:00.171141Z","shell.execute_reply":"2025-01-30T06:14:00.176215Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Define dataset paths\n\n#### Here, we specify the paths for training and test datasets.\n#### These directories contain images sorted into folders based on categories.\n","metadata":{}},{"cell_type":"code","source":"# Define dataset paths\n\"\"\"\nSpecify the paths to the training and testing datasets.\n\"\"\"\ntrain_path = \"/kaggle/input/waste-classification-data/DATASET/TRAIN\"\ntest_path = \"/kaggle/input/waste-classification-data/DATASET/TEST\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T06:14:00.178708Z","iopub.execute_input":"2025-01-30T06:14:00.178999Z","iopub.status.idle":"2025-01-30T06:14:00.182979Z","shell.execute_reply.started":"2025-01-30T06:14:00.178975Z","shell.execute_reply":"2025-01-30T06:14:00.181895Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualization\nfrom cv2 import cvtColor\nx_data = []\ny_data = []\nfor category in glob(train_path+'/*'):\n    for file in tqdm(glob(category+'/*')):\n        img_array = cv2.imread(file)\n        img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n        x_data.append(img_array)\n        y_data.append(category.split(\"/\")[-1])\ndata = pd.DataFrame({'image': x_data, 'label': y_data})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T06:14:00.184053Z","iopub.execute_input":"2025-01-30T06:14:00.184377Z","iopub.status.idle":"2025-01-30T06:14:49.651118Z","shell.execute_reply.started":"2025-01-30T06:14:00.184349Z","shell.execute_reply":"2025-01-30T06:14:49.649686Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.shape\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T06:14:49.652404Z","iopub.execute_input":"2025-01-30T06:14:49.652778Z","iopub.status.idle":"2025-01-30T06:14:49.659665Z","shell.execute_reply.started":"2025-01-30T06:14:49.652749Z","shell.execute_reply":"2025-01-30T06:14:49.658588Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"colors = ['#a0d157', '#c48bb8']\nplt.pie(data.label.value_counts(), labels=['Organic', 'Recyclable'], autopct='%0.2f%%',\n        colors=colors, startangle=90, explode=[0.05, 0.05])\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T06:14:49.660802Z","iopub.execute_input":"2025-01-30T06:14:49.661191Z","iopub.status.idle":"2025-01-30T06:14:49.783576Z","shell.execute_reply.started":"2025-01-30T06:14:49.661154Z","shell.execute_reply":"2025-01-30T06:14:49.78225Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(20, 15))\nfor i in range(9):\n    plt.subplot(4, 3,(i%12)+1)\n    index = np.random.randint(15000)\n    plt.title('This is of {0}'.format(data.label[index]))\n    plt.imshow(data.image[index])\n    plt.tight_layout()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T06:14:49.786005Z","iopub.execute_input":"2025-01-30T06:14:49.786342Z","iopub.status.idle":"2025-01-30T06:14:53.414051Z","shell.execute_reply.started":"2025-01-30T06:14:49.786312Z","shell.execute_reply":"2025-01-30T06:14:53.412501Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Augmentation to improve generalization\n\n#### Data augmentation helps the model generalize better by applying transformations\n#### such as rotation, zoom, and flipping to artificially increase dataset size.\n#### We use `ImageDataGenerator` with:\n#### - `rescale`: Normalize pixel values to [0,1]\n#### - `rotation_range`: Randomly rotate images\n#### - `width_shift_range` & `height_shift_range`: Shift images horizontally/vertically\n#### - `shear_range` & `zoom_range`: Apply shear and zoom effects\n#### - `horizontal_flip`: Flip images horizontally\n#### - `fill_mode`: Fill missing pixels with nearest values\n#### - `validation_split`: Split data into training and validation sets (80/20)\n","metadata":{}},{"cell_type":"code","source":"# Data Augmentation for better generalization\n\"\"\"\nWe use `ImageDataGenerator` to apply transformations such as:\n- Rotation, width/height shift, shear, zoom, and flipping\n- Rescaling pixel values to [0,1]\n- Splitting training data into training (80%) and validation (20%)\n\"\"\"\ndatagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=30,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest',\n    validation_split=0.2\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T06:14:53.416036Z","iopub.execute_input":"2025-01-30T06:14:53.416517Z","iopub.status.idle":"2025-01-30T06:14:53.423323Z","shell.execute_reply.started":"2025-01-30T06:14:53.416469Z","shell.execute_reply":"2025-01-30T06:14:53.42196Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load training and validation sets\n\n#### We create training and validation generators using the augmented dataset.\n#### - `target_size`: Resize images to 150x150 pixels\n#### - `batch_size`: Set batch size to 32 for optimal training speed\n#### - `class_mode`: Categorical classification for multiple classes\n#### - `subset`: 'training' for training set and 'validation' for validation set\n","metadata":{}},{"cell_type":"code","source":"# Load training and validation data\n\"\"\"\nGenerate training and validation datasets using augmentation.\nTarget size: 150x150 pixels, batch size: 32, class mode: categorical.\n\"\"\"\ntrain_generator = datagen.flow_from_directory(\n    train_path,\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='categorical',\n    subset='training'\n)\nvalidation_generator = datagen.flow_from_directory(\n    train_path,\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='categorical',\n    subset='validation'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T06:14:53.424661Z","iopub.execute_input":"2025-01-30T06:14:53.424943Z","iopub.status.idle":"2025-01-30T06:14:54.153121Z","shell.execute_reply.started":"2025-01-30T06:14:53.424919Z","shell.execute_reply":"2025-01-30T06:14:54.152192Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CNN - Convolutional Neural Network\n\n* ## Define an optimized CNN model\n\n#### We build a CNN model with:\n#### 1. **Conv2D layers** for feature extraction\n#### 2. **MaxPooling2D** for reducing spatial dimensions\n#### 3. **BatchNormalization** for stable training\n#### 4. **Flatten** to convert features into a dense layer\n#### 5. **Dense layers** for learning complex patterns\n#### 6. **Dropout (50%)** to prevent overfitting\n","metadata":{}},{"cell_type":"code","source":"#building a CNN model\n\ndef build_model():\n    model = Sequential([\n        Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),\n        MaxPooling2D(2,2),\n        BatchNormalization(),\n\n        Conv2D(64, (3,3), activation='relu'),\n        MaxPooling2D(2,2),\n        BatchNormalization(),\n\n        Conv2D(128, (3,3), activation='relu'),\n        MaxPooling2D(2,2),\n        BatchNormalization(),\n\n        Flatten(),\n        Dense(512, activation='relu'),\n        Dropout(0.5),\n        Dense(len(train_generator.class_indices), activation='softmax')\n    ])\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T06:14:54.154135Z","iopub.execute_input":"2025-01-30T06:14:54.154432Z","iopub.status.idle":"2025-01-30T06:14:54.160792Z","shell.execute_reply.started":"2025-01-30T06:14:54.154407Z","shell.execute_reply":"2025-01-30T06:14:54.159796Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Compile the CNN model\n\n### Use Adam optimizer with a learning rate of 0.0001 for smooth training.\n### Loss function: Categorical Crossentropy, suitable for multi-class classification.\n### Metric: Accuracy.\n","metadata":{}},{"cell_type":"code","source":"# Compile the CNN model\n\nmodel = build_model()\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T06:14:54.161817Z","iopub.execute_input":"2025-01-30T06:14:54.162204Z","iopub.status.idle":"2025-01-30T06:14:54.332915Z","shell.execute_reply.started":"2025-01-30T06:14:54.162165Z","shell.execute_reply":"2025-01-30T06:14:54.331938Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Display Model Summary\n\n### View the architecture and parameter count of the compiled CNN model.\n","metadata":{}},{"cell_type":"code","source":"# Display Model Summary\n\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T06:14:54.333697Z","iopub.execute_input":"2025-01-30T06:14:54.333956Z","iopub.status.idle":"2025-01-30T06:14:54.36122Z","shell.execute_reply.started":"2025-01-30T06:14:54.333933Z","shell.execute_reply":"2025-01-30T06:14:54.360172Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Implement early stopping and checkpointing\n\n### - **EarlyStopping**: Stops training when validation loss stops improving.\n### - **ModelCheckpoint**: Saves the best model during training.","metadata":{}},{"cell_type":"code","source":"# Implement early stopping and checkpointing\n\ncallbacks = [\n    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n    ModelCheckpoint('best_model.keras', save_best_only=True)  # Updated file format\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T06:16:06.199287Z","iopub.execute_input":"2025-01-30T06:16:06.199778Z","iopub.status.idle":"2025-01-30T06:16:06.205297Z","shell.execute_reply.started":"2025-01-30T06:16:06.199739Z","shell.execute_reply":"2025-01-30T06:16:06.203654Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train the CNN model\n\n### Train the model using 50 epochs and the augmented dataset.\n### Monitor validation accuracy to prevent overfitting.\n","metadata":{}},{"cell_type":"code","source":"# Train the CNN model\n\nhistory = model.fit(\n    train_generator,\n    validation_data=validation_generator,\n    epochs=50,\n    callbacks=callbacks\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T06:16:11.321884Z","iopub.execute_input":"2025-01-30T06:16:11.322286Z","iopub.status.idle":"2025-01-30T10:46:44.903293Z","shell.execute_reply.started":"2025-01-30T06:16:11.322258Z","shell.execute_reply":"2025-01-30T10:46:44.899989Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Save the trained model\n### Store the final trained model for future inference.","metadata":{}},{"cell_type":"code","source":"# Save the trained model\n\nmodel.save(\"Waste-Classification-CNN-Model.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T10:46:44.90828Z","iopub.execute_input":"2025-01-30T10:46:44.915177Z","iopub.status.idle":"2025-01-30T10:46:45.372991Z","shell.execute_reply.started":"2025-01-30T10:46:44.915107Z","shell.execute_reply":"2025-01-30T10:46:45.371933Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Plot training history\n\n### Visualize training and validation performance using Matplotlib.\n### - Accuracy curve shows model improvement.\n### - Loss curve indicates model convergence.\n","metadata":{}},{"cell_type":"code","source":"# Plot training history\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend()\nplt.title('Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend()\nplt.title('Loss')\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T10:46:45.37495Z","iopub.execute_input":"2025-01-30T10:46:45.375325Z","iopub.status.idle":"2025-01-30T10:46:45.870015Z","shell.execute_reply.started":"2025-01-30T10:46:45.375295Z","shell.execute_reply":"2025-01-30T10:46:45.868761Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load the Trained Model\n\n#### Now that our model is trained and saved, we load it back to perform predictions on new images.","metadata":{}},{"cell_type":"code","source":"# Load the Trained Model\n\nfrom tensorflow.keras.models import load_model\n\n# Load the best saved model\nmodel = load_model(\"Waste-Classification-CNN-Model.h5\")\n\n# Display the model architecture again to verify loading\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T11:03:11.631889Z","iopub.execute_input":"2025-01-30T11:03:11.633169Z","iopub.status.idle":"2025-01-30T11:03:11.98274Z","shell.execute_reply.started":"2025-01-30T11:03:11.633106Z","shell.execute_reply":"2025-01-30T11:03:11.981814Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Prepare Test Data\n\n#### - Define the path to the test dataset.\n#### - Create an image generator for rescaling.\n#### - Load test images in a format similar to the training dataset.","metadata":{}},{"cell_type":"code","source":"# Prepare Test Data\n\ntest_path = \"/kaggle/input/waste-classification-data/DATASET/TEST\"\n\n# Rescale test images to match training data\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# Load test dataset with similar preprocessing\ntest_generator = test_datagen.flow_from_directory(\n    test_path,\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='categorical',\n    shuffle=False  # Do not shuffle so that labels remain aligned\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T11:03:11.99463Z","iopub.execute_input":"2025-01-30T11:03:11.994976Z","iopub.status.idle":"2025-01-30T11:03:13.20541Z","shell.execute_reply.started":"2025-01-30T11:03:11.994951Z","shell.execute_reply":"2025-01-30T11:03:13.204307Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluate Model Performance on Test Data\n\n#### We check how well our model generalizes by testing it on unseen data.\n","metadata":{}},{"cell_type":"code","source":"# Evaluate model accuracy on test set\ntest_loss, test_accuracy = model.evaluate(test_generator)\n\nprint(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\nprint(f\"Test Loss: {test_loss:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T11:03:13.206863Z","iopub.execute_input":"2025-01-30T11:03:13.207155Z","iopub.status.idle":"2025-01-30T11:03:54.775111Z","shell.execute_reply.started":"2025-01-30T11:03:13.207127Z","shell.execute_reply":"2025-01-30T11:03:54.773526Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Make Predictions on Test Images\n\n#### We will predict classes for test images and compare them with true labels.","metadata":{}},{"cell_type":"code","source":"# Make Predictions on Test Images\n\nimport numpy as np\n\n# Get predictions (probabilities)\npredictions = model.predict(test_generator)\n\n# Convert probabilities to class labels\npredicted_classes = np.argmax(predictions, axis=1)\n\n# Get actual class labels from test generator\nactual_classes = test_generator.classes\n\n# Get class labels (to map indices back to names)\nclass_labels = list(test_generator.class_indices.keys())\n\n# Print sample predictions\nprint(\"Predicted Classes:\", [class_labels[i] for i in predicted_classes[:10]])\nprint(\"Actual Classes:\", [class_labels[i] for i in actual_classes[:10]])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T11:03:54.777895Z","iopub.execute_input":"2025-01-30T11:03:54.778376Z","iopub.status.idle":"2025-01-30T11:04:24.530114Z","shell.execute_reply.started":"2025-01-30T11:03:54.778341Z","shell.execute_reply":"2025-01-30T11:04:24.528953Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualize Predictions\n\n#### We randomly select some test images and display them with predicted labels.","metadata":{}},{"cell_type":"code","source":"\"\"\"\n# Visualize Some Test Images with Predictions\nWe randomly select some test images and display them with predicted labels.\n\"\"\"\nimport matplotlib.pyplot as plt\n\n# Get file names for test images\ntest_image_paths = test_generator.filepaths\n\n# Select random indices\nrandom_indices = np.random.choice(len(test_image_paths), 6, replace=False)\n\nplt.figure(figsize=(12, 6))\n\nfor i, idx in enumerate(random_indices):\n    img = cv2.imread(test_image_paths[idx])\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for correct color display\n\n    # Get predicted label\n    predicted_label = class_labels[predicted_classes[idx]]\n    actual_label = class_labels[actual_classes[idx]]\n\n    plt.subplot(2, 3, i + 1)\n    plt.imshow(img)\n    plt.axis('off')\n    plt.title(f\"Predicted: {predicted_label}\\nActual: {actual_label}\", fontsize=12)\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T11:04:24.531636Z","iopub.execute_input":"2025-01-30T11:04:24.531961Z","iopub.status.idle":"2025-01-30T11:04:25.217371Z","shell.execute_reply.started":"2025-01-30T11:04:24.53193Z","shell.execute_reply":"2025-01-30T11:04:25.215987Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Classification Report & Confusion Matrix\n\n#### This helps analyze model performance per class.","metadata":{}},{"cell_type":"code","source":"# Generate Classification Report and Confusion Matrix\n\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Print classification report\nprint(\"Classification Report:\\n\")\nprint(classification_report(actual_classes, predicted_classes, target_names=class_labels))\n\n# Generate and plot confusion matrix\nimport seaborn as sns\n\ncm = confusion_matrix(actual_classes, predicted_classes)\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T11:04:25.218564Z","iopub.execute_input":"2025-01-30T11:04:25.218908Z","iopub.status.idle":"2025-01-30T11:04:25.43316Z","shell.execute_reply.started":"2025-01-30T11:04:25.218879Z","shell.execute_reply":"2025-01-30T11:04:25.43207Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}